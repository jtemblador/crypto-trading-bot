{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b1820c42-73db-42b2-a63e-c09517abbda0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Import stuff\n",
    "import pandas as pd\n",
    "import zipfile\n",
    "import os\n",
    "from glob import glob\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "87c44c0f-1d80-4e9a-99c1-557f2b25fe70",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unzip_and_load_crypto(zip_folder_path):\n",
    "    all_crypto = []\n",
    "    zip_files = glob(os.path.join(zip_folder_path, '*.zip'))\n",
    "\n",
    "    for zip_file in zip_files:\n",
    "        with zipfile.ZipFile(zip_file, 'r') as zip_ref:\n",
    "            extract_path = os.path.splitext(zip_file)[0]\n",
    "            os.makedirs(extract_path, exist_ok=True)\n",
    "            zip_ref.extractall(extract_path)\n",
    "\n",
    "        csv_files = glob(os.path.join(extract_path, '*.csv'))\n",
    "        for csv in csv_files:\n",
    "            df = pd.read_csv(csv)\n",
    "            all_crypto.append(df)\n",
    "\n",
    "    crypto_df = pd.concat(all_crypto, ignore_index=True)\n",
    "    return crypto_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "471e5365-fb1a-4424-8cf6-3e622cbc66e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_reddit_sentiment(sentiment_folder_path):\n",
    "    all_reddit = []\n",
    "    csv_files = glob(os.path.join(sentiment_folder_path, '*.csv'))\n",
    "\n",
    "    for csv in csv_files:\n",
    "        if os.path.isfile(csv):  # Fix: only open real files\n",
    "            df = pd.read_csv(csv)\n",
    "            all_reddit.append(df)\n",
    "\n",
    "    reddit_df = pd.concat(all_reddit, ignore_index=True)\n",
    "    return reddit_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7e882f15-c2ef-43a8-ac8e-0c3d4daa0d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(crypto_df, reddit_df):\n",
    "    crypto_df['timestamp'] = pd.to_datetime(crypto_df['timestamp']) # Converts timestampl colums from string to datetime objs\n",
    "    reddit_df['timestamp'] = pd.to_datetime(reddit_df['timestamp'])\n",
    "\n",
    "    crypto_df.set_index('timestamp', inplace=True) # Set timestamp as the index of each DataFrame\n",
    "    reddit_df.set_index('timestamp', inplace=True)\n",
    "\n",
    "    # THIS SETS HOUR INTERVALSA, MAY CHANGE\n",
    "    crypto_hourly = crypto_df['close'].resample('h').last()  # Hour intervals, for now\n",
    "    reddit_hourly = reddit_df['sentiment'].resample('h').mean()\n",
    "\n",
    "    # Shift the crypto closing prices 6 hours backwards, for every hour we now have price 6 hours into FUTURE\n",
    "    future_price = crypto_hourly.shift(-6)  # 6 hours into future\n",
    "\n",
    "    # This DA DATA, contains everything listed under me\n",
    "    data = pd.DataFrame({\n",
    "        'sentiment': reddit_hourly,\n",
    "        'close_price': crypto_hourly,\n",
    "        'future_close_price': future_price\n",
    "    })\n",
    "\n",
    "    data.dropna(inplace=True) # Drops any rows where data is missing, Can happen if at beggining or end, or if no reddit post synced with kraken data\n",
    "    \n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0d4340d4-aa49-454d-974b-99d493fbd7c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_lagged_features(data, max_lag_hours=12):\n",
    "    for lag in range(1, max_lag_hours + 1):\n",
    "        data[f'sentiment_prev_{lag}h'] = data['sentiment'].shift(lag)\n",
    "        data[f'close_price_prev_{lag}h'] = data['close_price'].shift(lag)\n",
    "\n",
    "    # Create target: price movement 6 hours later\n",
    "    data['target'] = (data['future_close_price'] > data['close_price']).astype(int)\n",
    "\n",
    "    data.dropna(inplace=True)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "02a47238-8d01-4de0-bd78-801d22808d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(data):\n",
    "    feature_cols = [col for col in data.columns if 'sentiment' in col or 'close_price_prev' in col]\n",
    "    X = data[feature_cols]\n",
    "    y = data['target']\n",
    "\n",
    "    train_end = int(len(X) * 0.7)\n",
    "    valid_end = int(len(X) * 0.85)\n",
    "\n",
    "    X_train = X.iloc[:train_end]\n",
    "    y_train = y.iloc[:train_end]\n",
    "\n",
    "    X_valid = X.iloc[train_end:valid_end]\n",
    "    y_valid = y.iloc[train_end:valid_end]\n",
    "\n",
    "    X_test = X.iloc[valid_end:]\n",
    "    y_test = y.iloc[valid_end:]\n",
    "\n",
    "    return X_train, X_valid, X_test, y_train, y_valid, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2f532ad0-05f5-40d1-92cf-a19fb24f6d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate(X_train, X_valid, X_test, y_train, y_valid, y_test):\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_valid_scaled = scaler.transform(X_valid)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    print(\"[INFO] Training SVM model...\")\n",
    "    svm_model = SVC(kernel='rbf')\n",
    "    svm_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "    y_test_pred_svm = svm_model.predict(X_test_scaled)\n",
    "\n",
    "    print(\"\\nSVM Model Test Set Performance:\")\n",
    "    print(classification_report(y_test, y_test_pred_svm))\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(confusion_matrix(y_test, y_test_pred_svm))\n",
    "    print(f\"Accuracy: {accuracy_score(y_test, y_test_pred_svm):.4f}\")\n",
    "    print(f\"Precision: {precision_score(y_test, y_test_pred_svm):.4f}\")\n",
    "    print(f\"Recall: {recall_score(y_test, y_test_pred_svm):.4f}\")\n",
    "    print(f\"F1 Score: {f1_score(y_test, y_test_pred_svm):.4f}\")\n",
    "\n",
    "    print(\"\\n[INFO] Training XGBoost model...\")\n",
    "    xgb_model = xgb.XGBClassifier(use_label_encoder=False, eval_metric='logloss')\n",
    "    xgb_model.fit(X_train, y_train)\n",
    "\n",
    "    y_test_pred_xgb = xgb_model.predict(X_test)\n",
    "\n",
    "    print(\"\\nXGBoost Model Test Set Performance:\")\n",
    "    print(classification_report(y_test, y_test_pred_xgb))\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(confusion_matrix(y_test, y_test_pred_xgb))\n",
    "    print(f\"Accuracy: {accuracy_score(y_test, y_test_pred_xgb):.4f}\")\n",
    "    print(f\"Precision: {precision_score(y_test, y_test_pred_xgb):.4f}\")\n",
    "    print(f\"Recall: {recall_score(y_test, y_test_pred_xgb):.4f}\")\n",
    "    print(f\"F1 Score: {f1_score(y_test, y_test_pred_xgb):.4f}\")\n",
    "\n",
    "    return svm_model, xgb_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e7aa4b23-6ca6-441b-8efd-98765fcac73c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    crypto_folder = 'data/'  # update this\n",
    "    reddit_folder = 'data/'   # update this\n",
    "\n",
    "    print(\"[INFO] Loading crypto data...\")\n",
    "    crypto_df = unzip_and_load_crypto(crypto_folder)\n",
    "\n",
    "    print(\"[INFO] Loading reddit sentiment data...\")\n",
    "    reddit_df = load_reddit_sentiment(reddit_folder)\n",
    "\n",
    "    print(\"[INFO] Preprocessing data...\")\n",
    "    data = preprocess_data(crypto_df, reddit_df)\n",
    "\n",
    "    print(\"[INFO] Creating lagged features...\")\n",
    "    data = create_lagged_features(data, max_lag_hours=12)\n",
    "\n",
    "    print(\"[INFO] Splitting data...\")\n",
    "    X_train, X_valid, X_test, y_train, y_valid, y_test = split_data(data)\n",
    "\n",
    "    print(\"[INFO] Training and evaluating model...\")\n",
    "    model = train_and_evaluate(X_train, X_valid, X_test, y_train, y_valid, y_test)\n",
    "\n",
    "    print(\"[INFO] Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a9e1f870-923d-4257-90e3-628e03421f62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Loading crypto data...\n",
      "[INFO] Loading reddit sentiment data...\n",
      "[INFO] Preprocessing data...\n",
      "[INFO] Creating lagged features...\n",
      "[INFO] Splitting data...\n",
      "[INFO] Training and evaluating model...\n",
      "[INFO] Training SVM model...\n",
      "\n",
      "SVM Model Test Set Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.22      0.34        50\n",
      "           1       0.30      0.81      0.44        21\n",
      "\n",
      "    accuracy                           0.39        71\n",
      "   macro avg       0.52      0.51      0.39        71\n",
      "weighted avg       0.61      0.39      0.37        71\n",
      "\n",
      "Confusion Matrix:\n",
      "[[11 39]\n",
      " [ 4 17]]\n",
      "Accuracy: 0.3944\n",
      "Precision: 0.3036\n",
      "Recall: 0.8095\n",
      "F1 Score: 0.4416\n",
      "\n",
      "[INFO] Training XGBoost model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xyz/.local/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [17:00:41] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "XGBoost Model Test Set Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.32      0.44        50\n",
      "           1       0.31      0.71      0.43        21\n",
      "\n",
      "    accuracy                           0.44        71\n",
      "   macro avg       0.52      0.52      0.44        71\n",
      "weighted avg       0.60      0.44      0.44        71\n",
      "\n",
      "Confusion Matrix:\n",
      "[[16 34]\n",
      " [ 6 15]]\n",
      "Accuracy: 0.4366\n",
      "Precision: 0.3061\n",
      "Recall: 0.7143\n",
      "F1 Score: 0.4286\n",
      "[INFO] Done.\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6a6dfe7-b980-4050-84cb-336c8d67b7ff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
